taxa <- cbind(taxa, sequence = seqs)
classified <- classified_taxa(feature_table, taxa)
flog.info("Reads with taxonomic classification: %s", classified[,
paste(rank, "=", 100 * round(reads, 3), "%", collapse = ",")])
if (config$hash) {
flog.info("Hashing %d sequence variants.", nrow(taxa))
seqs <- rownames(taxa)
hashes <- sapply(seqs, digest)
names(seqs) <- hashes
rownames(taxa) <- hashes
colnames(feature_table_nochim) <- hashes[colnames(feature_table_nochim)]
}
artifact <- list(feature_table = feature_table_nochim, taxonomy = taxa,
errors = errors, error_plots = lapply(errors, function(x) lapply(x,
plotErrors, nominalQ = TRUE)), passed_reads = dada_stats,
classified = classified, steps = c(object[["steps"]],
"denoise"))
return(artifact)
}
denoised <- processed %>% denoiseMod(config$denoise)
edit(denoise())
edit(denoise
)
denoised <- processed %>% denoise(config$denoise)
edit(denoise)
denoised <- processed %>% denoise(config$denoise)
denoised
edit(denoise)
denoise
config <- list(
threads=4,
preprocess = config_preprocess(
trunLen = c(148, 140)  # forward and reverse truncation
),
denoise = config_denoise(minOverlap = 3)  # will only use defaults
)
denoise
edit(denoise)
denoiseMod<-function (object, config)
{ env.profile("mbtools")
files <- get_files(object)
files <- copy(files)
if (!"run" %in% names(files)) {
files[, `:=`("run", "all")]
}
paired <- "reverse" %in% names(files)
flog.info("Running DADA2 on %d run(s) from a sample of up to %.3g bases.",
files[, uniqueN(run)], config$nbases)
errors <- list()
dada_stats <- list()
feature_table <- list()
for (r in files[, unique(run)]) {
fi <- files[run == r]
dada_stats[[r]] <- data.table(id = fi$id)
flog.info("Learning errors for run `%s` (%d samples)...",
r, nrow(fi))
errors[[r]] <- list()
errors[[r]][["forward"]] <- learnErrors(fi$forward, nbases = config$nbases,
multithread = config$threads, verbose = 0)
if (paired) {
errors[[r]][["reverse"]] <- learnErrors(fi$reverse,
nbases = config$nbases, multithread = config$threads,
verbose = 0)
}
flog.info("Dereplicating run `%s` (%d samples)...", r,
nrow(fi))
derep_forward <- derepFastq(fi$forward)
dada_stats[[r]][, `:=`("derep_forward", getN(derep_forward))]
if (paired) {
derep_reverse <- derepFastq(fi$reverse, )
dada_stats[[r]][, `:=`("derep_reverse", getN(derep_reverse))]
}
flog.info("Inferring sequence variants for run `%s`...",
r)
dada_forward <- dada(derep_forward, err = errors[[r]]$forward,
multithread = config$threads, verbose = 0, pool = config$pool)
dada_stats[[r]][, `:=`("denoised_forward", getN(dada_forward))]
if (paired) {
dada_reverse <- dada(derep_reverse, err = errors[[r]]$reverse,
multithread = config$threads, verbose = 0, pool = config$pool)
dada_stats[[r]][, `:=`("denoised_reverse", getN(dada_reverse))]
merged <- mergePairs(dada_forward, derep_forward,
dada_reverse, derep_reverse, verbose = 0,minOverlap = 4)
dada_stats[[r]][, `:=`("merged", getN(merged))]
feature_table[[r]] <- makeSequenceTable(merged)
}
else {
feature_table[[r]] <- makeSequenceTable(dada_forward)
}
rownames(feature_table[[r]]) <- fi$id
flog.info("Finished run `%s`.", r)
}
return
feature_table <- mergeSequenceTables(tables = feature_table)
dada_stats <- rbindlist(dada_stats)
if ("passed" %in% names(object)) {
dada_stats <- object$passed[dada_stats, on = "id"]
}
flog.info("Merged sequence tables, now removing chimeras...")
feature_table_nochim <- removeBimeraDenovo(feature_table,
multithread = config$threads)
flog.info("Removed %d/%d sequence variants as chimeric (%.2f%% of reads)",
ncol(feature_table) - ncol(feature_table_nochim), ncol(feature_table),
100 - 100 * sum(feature_table_nochim)/sum(feature_table))
dada_stats[, `:=`("non_chimera", rowSums(feature_table_nochim)[id])]
flog.info("Assigning taxonomy to %d sequences...", ncol(feature_table_nochim))
tmp <- tempdir()
if (grepl("tp(s*)://", config$taxa_db)) {
taxa_db <- file.path(tmp, "taxa.fna.gz")
flog.info("Downloading taxa db to %s...", taxa_db)
download.file(config$taxa_db, taxa_db)
}
else {
taxa_db <- config$taxa_db
}
if (grepl("tp(s*)://", config$species_db)) {
species_db <- file.path(tmp, "species.fna.gz")
flog.info("Downloading taxa db to %s...", species_db)
download.file(config$species_db, species_db)
}
else {
species_db <- config$taxa_db
}
taxa <- assignTaxonomy(feature_table_nochim, taxa_db, minBoot = config$bootstrap_confidence *
100, multithread = config$threads)
taxa <- addSpecies(taxa, species_db)
seqs <- rownames(taxa)
taxa <- cbind(taxa, sequence = seqs)
classified <- classified_taxa(feature_table, taxa)
flog.info("Reads with taxonomic classification: %s", classified[,
paste(rank, "=", 100 * round(reads, 3), "%", collapse = ",")])
if (config$hash) {
flog.info("Hashing %d sequence variants.", nrow(taxa))
seqs <- rownames(taxa)
hashes <- sapply(seqs, digest)
names(seqs) <- hashes
rownames(taxa) <- hashes
colnames(feature_table_nochim) <- hashes[colnames(feature_table_nochim)]
}
artifact <- list(feature_table = feature_table_nochim, taxonomy = taxa,
errors = errors, error_plots = lapply(errors, function(x) lapply(x,
plotErrors, nominalQ = TRUE)), passed_reads = dada_stats,
classified = classified, steps = c(object[["steps"]],
"denoise"))
return(artifact)
}
denoised <- processed %>% denoiseMod(config$denoise)
modify(denoise())
modify(denoise
modify(denoise)
denoise<-edit(denoise)
denoised <- processed %>% denoise(config$denoise)
ps <- as_phyloseq(denoised)
ps
asv_counts <- taxa_count(ps, lev = NA)
asv_counts
asv_counts <- taxa_count(ps, lev = 1)
deno
denoised
denoised$classified
asv_counts
asv_counts$species
unique(asv_counts$species)
plot_taxa(ps)
?assignTaxonomy
config$bootstrap_confidence
subset(asv_counts,species=="Akkermansia municiphila"
)
subset(asv_counts,species==""
subset(asv_counts,species=="Akkermansia muciniphila")
subset(asv_counts,species=="Bifidobacterium NA")
subset(asv_counts,species=="Lactobacillus NA")
library("RforProteomics")
library("BiocInstaller")
biocLite("RforProteomics")
biocLite("DEqMS")
BiocManager::install("DEqMS")
library("DEqMS")
url <- "ftp://ftp.pride.ebi.ac.uk/pride/data/archive/2016/06/PXD004163/Yan_miR_Protein_table.flatprottable.txt"
download.file(url, destfile = "./miR_Proteintable.txt",method = "auto")
df.prot = read.table("miR_Proteintable.txt",stringsAsFactors = FALSE,
header = TRUE, quote = "", comment.char = "",sep = "\t")
df.prot
install.packages("RSQLite")
library(DBI)
install.packages("RSQLite")
library(DBI)
install.packages("RSQLite")
install.packages("RSQLite")
install.packages("RSQLite")
library(DBI)
TMT_columns = seq(15,33,2)
dat = df.prot[df.prot$miR.FASP_q.value<0.01,TMT_columns]
rownames(dat) = df.prot[df.prot$miR.FASP_q.value<0.01,]$Protein.accession
head(dat)
head(df.prot)
head(dat)
library(plyr)
library(dplyr)
data.table::fread("~/Desktop/proteinGroups.txt")
data<-data.table::fread("~/Desktop/proteinGroups.txt")
colnames(data)
data[1,]
colnames(data)
intensities<-log2(data[,195:218]+1)
intensities[intensities==0]<-NA
boxplot(intensities,las=2)
intensities<-data[,195:218]
intensities<-intensities/colSums(intensities)
intensities
intensities<-data[,195:218]
colSums(intensities)
intensities<-data[,195:218]
intensities
intensities+1
intensities<-t(t(intensities)/colSums(intensities))
intensities<-data[,195:218]
intensities<-t(t(intensities)/colSums(intensities))
intensities
intensities[intensities==0]<-NA
boxplot(intensities,las=2)
boxplot(log2(intensities),las=2)
intensities<-data[,195:218]
boxplot(log2(intensities),las=2)
data<-data.table::fread("~/Desktop/proteinGroups_allgroups.txt")
colnames(data)
intensities<-data[,53:58]
intensities
data[,46:58]
boxplot(log2(intensities+1),las=2)
is.na(log2(intensities+1)==0)
(log2(intensities+1)==0)
isTRUE(log2(intensities+1)==0)
(log2(intensities+1)==0)
!(log2(intensities+1)==0)
colSums(!(log2(intensities+1)==0))
library(plyr)
library(dplyr)
data<-data.table::fread("/Volumes/Said/proteinGroups.txt")
colnames(data)
intensities<-data[,69:74]
intensities<-t(t(intensities)/colSums(intensities))
intensities[intensities==0]<-NA
boxplot(log2(intensities),las=2)
data<-data.table::fread("/Volumes/Said/Proteomics_FlashLFQ_QuantifiedProteins.tsv")
data
data$V47
table(data$V47)
data
colnames(data)
boxplot(data[,4:46])
boxplot(log2(data[,4:46]+1)
)
boxplot(data[,4:46])
intensities<-data[,4:46]
intensities[intensities==0]<-NA
boxplot(intensities,las=2)
intensities<-t(t(intensities)/colSums(intensities))
boxplot(log2(intensities),las=2)
intensities[intensities==0]<-NA
boxplot(log2(intensities),las=2)
intensities<-data[,4:46]
intensities<-t(t(intensities)/colSums(intensities))
intensities[intensities==0]<-NA
boxplot(log2(intensities),las=2)
colnames(data)
grep("Intensity_","",colnames(data))
gsub("Intensity_","",colnames(data))
colnames(data)<-gsub("Intensity_","",colnames(data))
data$`E1-C-C`+data$`E2-C-C-p1`
colnames(data)
data$`E1-C-C`=data$`E1-C-C`+data$`E1-C-C-p1`
data$`E2-C-C`=data$`E2-C-C`+data$`E2-C-C-p1`
data$`E3-C-C`=data$`E3-C-C`+data$`E3-C-C-p1`
data$`E4-C-C`=data$`E4-C-C`+data$`E4-C-C-p1`
head(data)
data$`E1-C-S`=data$`E1-C-S`+data$`E1-C-S-p1`
data$`E2-C-S`=data$`E2-C-S`+data$`E2-C-S-p1`
data$`E3-C-S`=data$`E3-C-S`+data$`E3-C-S-p1`
data$`E4-C-S`=data$`E4-C-S`+data$`E4-C-S-p1`
data$`E1-C-M`=data$`E1-C-M`+data$`E1-C-M-p1`
data$`E2-C-M`=data$`E2-C-M`+data$`E2-C-M-p1`
data$`E3-C-M`=data$`E3-C-M`+data$`E3-C-M-p1`
data$`E4-C-M`=data$`E4-C-M`+data$`E4-C-M-p1`
data$`E1-WD-C`=data$`E1-WD-C`+data$`E1-WD-C-p1`
data$`E2-WD-C`=data$`E2-WD-C`+data$`E2-WD-C-p1`
data$`E3-WD-C`=data$`E3-WD-C`+data$`E3-WD-C-p1`
data$`E4-WD-C`=data$`E4-WD-C`+data$`E4-WD-C-p1`
data$`E1-WD-S`=data$`E1-WD-S`+data$`E1-WD-S-p1`
data$`E2-WD-S`=data$`E2-WD-S`+data$`E2-WD-S-p1`
data$`E3-WD-S`=data$`E3-WD-S`+data$`E3-WD-S-p1`
data$`E4-WD-S`=data$`E4-WD-S`+data$`E4-WD-S-p1`
data$`E1-WD-M`=data$`E1-WD-M`+data$`E1-WD-M-p1`
data$`E2-WD-M`=data$`E2-WD-M`+data$`E2-WD-M-p1`
data$`E3-WD-M`=data$`E3-WD-M`+data$`E3-WD-M-p1`
data$`E4-WD-M`=data$`E4-WD-M`+data$`E4-WD-M-p1`
colnames(data)
which(colnames(data)==c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M"))
colnames(data)==c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")
colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")
data[,colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")]
data[,(colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M"))]
data
data[,(colnames(data)%in% c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M"))]
data[,match(colnames(data)%in% c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M"))]
data[,match(colnames(data), c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M"))]
data[,1]
data[,2]
data[,3]
data[,4]
data[,5]
colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")
1:48[colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")]
c(1:48)[colnames(data)%in%c("E1-C-C","E2-C-C","E3-C-C","E4-C-C","E1-C-S","E2-C-S","E3-C-S","E4-C-S","E1-C-M","E2-C-M","E3-C-M","E4-C-M","E1-WD-C","E2-WD-C","E3-WD-C","E4-WD-C","E1-WD-S","E2-WD-S","E3-WD-S","E4-WD-S","E1-WD-M","E2-WD-M","E3-WD-M","E4-WD-M")]
data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)]
boxplot(data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)])
boxplot(log2(data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)]))
boxplot(log2(data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)])+1)
boxplot(log2(data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)]+1))
intensities<-data[,c(4,5,7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 48)]
intensities<-t(t(intensities)/colSums(intensities))
intensities[intensities==0]<-NA
boxplot(log2(intensities),las=2)
data<-data.table::fread("/Volumes/Said/Proteomics_FlashLFQ_QuantifiedProteins.tsv")
colnames(data)<-gsub("Intensity_","",colnames(data))
colnames(data)
data<-data.table::fread("/Volumes/Said/proteinGroups.txt")
colnames(data)
intensities<-data[,194:217]
intensities<-t(t(intensities)/colSums(intensities))
intensities[intensities==0]<-NA
boxplot(log2(intensities),las=2)
colSums(!is.na(intensities))
dim(data)
library(BiocManager)
biocLite("DEP")
biocLite("DEP")
source("https://bioconductor.org/biocLite.R")
biocLite("DEP")
library(DEP)
data <- UbiLength
expdesign <- UbiLength_ExpDesign
data
head(data)
results <- LFQ(data, expdesign, 'MinProb', 'control', 'Ctrl')
expdesign
biocLite("qiime2R")
install.packages("qiime2R")
devtools::install_github("jbisanz/MicrobeR")
biocLite("philr")
biocLite("DECIPHER")
devtools::install_github("jbisanz/MicrobeR")
biocLite("MicrobeR")
install_github(“jbisanz/MicrobeR”)
install_github("jbisanz/MicrobeR)
install_github("jbisanz/MicrobeR")
devtools::install_github("jbisanz/MicrobeR")
install_github("jbisanz/MicrobeR")
library(DEP)
dim(data)
data<-data.table::fread("/Volumes/Said/proteinGroups.txt")
setwd("~/Github/Tools/Proteomics/")
source('~/Github/Tools/Proteomics/Filtering_Maxquant_Diet_Project.R')
# Importing files ---------------------------------------------------------
setwd("~/Github/Tools/Proteomics/")
data<-data.table::fread("proteinGroups.txt")
data
# Libraries ---------------------------------------------------------------
# source("https://bioconductor.org/biocLite.R")
# biocLite("DEP")
library("DEP")
library("plyr")
library("dplyr")
designmatrix<-matrix(0,nrow = 24,ncol = 6)
colnames(designmatrix)<-c("C-C","C-M","C-S","WD-C","WD-M","WD-S")
rep(c("A","B"),each=1)
rep(c("A","B"),each=2)
paste(rep(c("A","B"),each=2),"_",rep(c("1","2"),each=2),sep="")
paste(rep(c("A","B"),each=2),"_",rep(c("1","2")),sep="")
paste(rep(c("A","B"),each=3),"_",rep(c("1","2")),sep="")
paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=3),"_",rep(c("1","2","3","4")),sep="")
rownames(designmatrix)<-paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=3),"_",rep(c("1","2","3","4")),sep="")
dim(designmatrix)
rownames(designmatrix)<-paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),"_",rep(c("1","2","3","4")),sep="")
designmatrix[1:4,1]<-1
designmatrix[5:8,2]<-1
designmatrix[9:12,3]<-1
designmatrix[13:16,4]<-1
designmatrix[17:20,5]<-1
designmatrix[21:24,6]<-1
designmatrix
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix)
as.data.frame(designmatrix)
designmatrix<-as.data.frame(designmatrix)
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix)
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C-C")
expdesign
rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4)
designmatrix<-data.frame(label=paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),"_",rep(c("1","2","3","4")),sep=""),
condition=rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),
replicate=rep(1:4,times=6)) matrix(0,nrow = 24,ncol = 6)
designmatrix<-data.frame(label=paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),"_",rep(c("1","2","3","4")),sep=""),
condition=rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),
replicate=rep(1:4,times=6))
designmatrix
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C-C")
colnames(data)
gsub(" ","."colnames(data)
gsub(" ",".",colnames(data)
)
colnames(data)<-gsub(" ",".",colnames(data))
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C-C")
UbiLength
colnames(UbiLength)
colnames(UbiLength) %in% colnames(data)
match(colnames(data),colnames(UbiLength))
match(colnames(UbiLength),colnames(data))
colnames(data)
match(colnames(UbiLength),colnames(data))
data<-data[,c(1,2,6,7,58,60,61,62,194:217,243:245)]
colnames(data)
gsub("+",".",colnames(data))
gsub("\\+",".",colnames(data))
colnames(data)<-gsub("\\+",".",colnames(data))
data<-data[,c(1,2,6,7,58,60,61,62,194:217,243:245)]
data<-data.table::fread("proteinGroups.txt")
colnames(data)<-gsub(" ",".",colnames(data))
colnames(data)<-gsub("\\+",".",colnames(data))
data<-data[,c(1,2,6,7,58,60,61,62,194:217,243:245)]
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C-C")
LFQ
data$Gene.names%>%duplicated()%>%any()
library("dplyr")
data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")
data_unique
head(data_unique)
colnames(data_unique)
# Cleaning data -----------------------------------------------------------
LFQ(data_unique,designmatrix,"MinProb","all","C-C")
LFQ
sapply(data, class)
sapply(UbiLength, class)
sapply(UbiLength_ExpDesign, class)
sapply(expdesign, class)
sapply(designmatrix, class)
designmatrix<-data.frame(label=paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),"_",rep(c("1","2","3","4")),sep=""),
condition=rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),
replicate=rep(1:4,times=6),stringsAsFactors=FALSE)
sapply(designmatrix, class)
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C-C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all","C.C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all",c("C.C","WD.C"))
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all",c("C.C"))
rownames(data)
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","all",c("C.C"))
rlang::last_error()
rlang::last_trace()
rlang::last_trace()
rlang::last_error()
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"Perseus-type","all",c("C.C"))
rlang::last_error()
rlang::last_trace()
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","manual",test=c("C.S_vs_C.C"))
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb","manual",test=c("C.S_vs_C.C"))
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb",type="manual",test=c("C.S_vs_C.C"))
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,"MinProb",type="manual",test="C.S_vs_C.C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,fun = "MinProb",type="manual",test="C.S_vs_C.C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,fun = "MinProb",type='manual',test="C.S_vs_C.C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,fun = "MinProb",type='manual',test="C.S_vs_C.C")
# Cleaning data -----------------------------------------------------------
LFQ(data,designmatrix,fun = "knn",type='manual',test="C.S_vs_C.C")
data <- UbiLength
expdesign <- UbiLength_ExpDesign
results <- LFQ(data, expdesign, 'MinProb', 'control', 'Ctrl')
rlang::last_error()
rlang::last_trace()
write.table(designmatrix,file="matrixdesign.tsv",quote = F,row.names = FALSE)
designmatrix
data<-data.table::fread("proteinGroups.txt")
colnames(data)<-gsub(" ",".",colnames(data))
colnames(data)<-gsub("\\+",".",colnames(data))
designmatrix<-data.frame(label=paste(rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),"_",rep(c("1","2","3","4")),sep=""),
condition=rep(c("C-C","C-M","C-S","WD-C","WD-M","WD-S"),each=4),
replicate=rep(1:4,times=6),stringsAsFactors=FALSE)
data<-data[,c(1,2,6,7,58,60,61,62,194:217,243:245)]
write.table(data,file="proteinGroups_preprocess.txt",quote = F,row.names = FALSE)
write.table(designmatrix,file="matrixdesign.tsv",quote = F)
write.table(data,file="proteinGroups_preprocess.txt",quote = F)
data<-data.table::fread("proteinGroups.txt")
data<-data[,c(1,2,6,7,58,60,61,62,194:217,243:245)]
write.table(data,file="proteinGroups_preprocess.txt",quote = F)
write.table(data,file="proteinGroups_preprocess.txt",quote = F,sep="\t")
write.table(designmatrix,file="matrixdesign.tsv",quote = F,sep="\t")
